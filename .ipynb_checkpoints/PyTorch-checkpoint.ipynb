{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unable-atmosphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import imageio\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "failing-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('house_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lined-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotFrontage'] = df['LotFrontage'].fillna(0)\n",
    "df['MasVnrArea'] = df['MasVnrArea'].fillna(0)\n",
    "df['GarageYrBlt'] = df['GarageYrBlt'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rapid-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "auburn-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "independent-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "signed-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.pop('SalePrice').values\n",
    "X = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "likely-crash",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-05fe6cac20a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m X_train, X_validation, Y_train, Y_validation = train_test_split(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2175\u001b[1;33m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0m\u001b[0;32m   2176\u001b[0m                                               default_test_size=0.25)\n\u001b[0;32m   2177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1856\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1857\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1858\u001b[0m             \u001b[1;34m'With n_samples={}, test_size={} and train_size={}, the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1859\u001b[0m             \u001b[1;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.20,\n",
    "    random_state=1,\n",
    "    shuffle=True\n",
    ")\n",
    "X_validation_numpy = np.asarray(X_validation).astype('float32')\n",
    "X_train_numpy = np.asarray(X_train).astype('float32')\n",
    "Y_train_numpy = np.asarray(Y_train).astype('float32')\n",
    "Y_validation_numpy = np.asarray(Y_validation).astype('float32')\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train_numpy)\n",
    "Y_train_tensor = torch.from_numpy(Y_train_numpy)\n",
    "X_validation_tensor = torch.from_numpy(X_validation_numpy)\n",
    "Y_validation_tensor = torch.from_numpy(Y_validation_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "sct = MinMaxS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train_tensor\n",
    "y = Y_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = Variable(x), Variable(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-monitoring",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.title('Regression Analysis')\n",
    "plt.scatter(y.data.numpy(), y.data.numpy(), color = \"orange\")\n",
    "plt.xlim(0, 1000000)\n",
    "plt.ylim(0, 1000000)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Prediction')\n",
    "plt.show()\n",
    "\n",
    "# this is one way to define a network\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "\n",
    "reg_model = torch.nn.Linear(in_features=features_num, out_features=1, bias=True)    \n",
    "\n",
    "net = Net(n_feature=features_num, n_hidden=10, n_output=1)     # define the network\n",
    "# print(net)  # net architecture\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "optimizer = torch.optim.SGD(reg_model.parameters(), lr=0.002)\n",
    "\n",
    "my_images = []\n",
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "# train the network\n",
    "for t in range(200):\n",
    "  \n",
    "    prediction = reg_model(x)     # input x and predict based on x\n",
    "\n",
    "    loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    \n",
    "    # plot and show learning process\n",
    "    plt.cla()\n",
    "    ax.set_title('Regression Analysis', fontsize=35)\n",
    "    ax.set_xlabel('Actual', fontsize=24)\n",
    "    ax.set_ylabel('Prediction', fontsize=24)\n",
    "    ax.set_xlim(0, 1000000)\n",
    "    ax.set_ylim(-500, 1000000)\n",
    "    ax.scatter(y.data.numpy(), prediction.data.numpy(), color = \"orange\")\n",
    "    ax.text(800000, 100000, 'Step = %d' % t, fontdict={'size': 24, 'color':  'red'})\n",
    "    ax.text(800000, 200000, 'Loss = %.4f' % loss.data.numpy(),\n",
    "            fontdict={'size': 24, 'color':  'red'})\n",
    "\n",
    "    # Used to return the plot as an image array \n",
    "    # (https://ndres.me/post/matplotlib-animated-gifs-easily/)\n",
    "    fig.canvas.draw()       # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    my_images.append(image)\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "# save images as a gif    \n",
    "imageio.mimsave('./curve_1.gif', my_images, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-discretion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-threshold",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax.set_title('Regression Analysis', fontsize=35)\n",
    "ax.set_xlabel('Actual', fontsize=24)\n",
    "ax.set_ylabel('Prediction', fontsize=24)\n",
    "plt.scatter(y.data.numpy(), pred.data.numpy(), color = \"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-location",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
